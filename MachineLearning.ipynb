{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Anomaly_Detector.py\n",
    "Used to preprocess data and detect possible outliers that might corrupt the model training.\n",
    "Parameters:\n",
    "\t\t- GPS latitude increments threshold (0.2).\n",
    "\t\t- GPS longitude increments threshold (0.2).\n",
    "\t\t- GPS altitude increments threshold (500).\n",
    "\t\t- Timestamp value length (27).\n",
    "\t\t- Z-axis magnetometer value threshold (2000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [3], line 56\u001B[0m\n\u001B[0;32m     53\u001B[0m gps_output \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mopen\u001B[39m(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124msensoringData_gps_clean.csv\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mw\u001B[39m\u001B[38;5;124m'\u001B[39m, newline\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m     55\u001B[0m     \u001B[38;5;66;03m# 0.2, 0.2, 27, 2000, 500\u001B[39;00m\n\u001B[1;32m---> 56\u001B[0m anomaly_detection(acc_input, acc_output, \u001B[38;5;28;43mfloat\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margv\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mfloat\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m2\u001B[39m]), \u001B[38;5;28mint\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m3\u001B[39m]), \u001B[38;5;28mint\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m4\u001B[39m]),\n\u001B[0;32m     57\u001B[0m                       \u001B[38;5;28mfloat\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m5\u001B[39m]), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124macc\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     58\u001B[0m anomaly_detection(gyro_input, gyro_output, \u001B[38;5;28mfloat\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m1\u001B[39m]), \u001B[38;5;28mfloat\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m2\u001B[39m]), \u001B[38;5;28mint\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m3\u001B[39m]),\n\u001B[0;32m     59\u001B[0m                       \u001B[38;5;28mint\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m4\u001B[39m]), \u001B[38;5;28mfloat\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m5\u001B[39m]), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mgyro\u001B[39m\u001B[38;5;124m'\u001B[39m)\n\u001B[0;32m     60\u001B[0m anomaly_detection(magn_input, magn_output, \u001B[38;5;28mfloat\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m1\u001B[39m]), \u001B[38;5;28mfloat\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m2\u001B[39m]), \u001B[38;5;28mint\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m3\u001B[39m]),\n\u001B[0;32m     61\u001B[0m                       \u001B[38;5;28mint\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m4\u001B[39m]), \u001B[38;5;28mfloat\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m5\u001B[39m]), \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mmagn\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "\u001B[1;31mValueError\u001B[0m: could not convert string to float: '-f'"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "\n",
    "def anomaly_detection(inp, out, th_lat, th_long, th_timestamp, th_sensor, th_alt, type):\n",
    "    writer = csv.writer(out, delimiter=\",\")\n",
    "\n",
    "    for row in csv.reader(inp):\n",
    "        if row[0] != \"id\":\n",
    "            if type == 'gps':\n",
    "                gps_lat_increment = float(row[3])\n",
    "                gps_long_increment = float(row[4])\n",
    "                gps_alt_increment = float(row[5])\n",
    "            else:\n",
    "                gps_lat_increment = 0.0\n",
    "                gps_long_increment = 0.0\n",
    "                gps_alt_increment = 0.0\n",
    "            if type == 'magn':\n",
    "                magn_z = float(row[5])\n",
    "            else:\n",
    "                magn_z = 0.0\n",
    "            timestamp = row[2]\n",
    "            if (gps_lat_increment < th_lat) and (gps_long_increment < th_long) and (len(timestamp) < th_timestamp) and \\\n",
    "                    (not timestamp.startswith('1970')) and (magn_z < th_sensor) and (gps_alt_increment < th_alt):\n",
    "                writer.writerow(row)\n",
    "            else:\n",
    "                if gps_lat_increment >= th_lat:\n",
    "                    print(\"GPS Latitude increment too high: \" + str(gps_lat_increment))\n",
    "                if gps_long_increment >= th_long:\n",
    "                    print(\"GPS Longitude increment too high: \" + str(gps_long_increment))\n",
    "                if gps_alt_increment >= th_alt:\n",
    "                    print(\"GPS Altitude increment too high: \" + str(gps_alt_increment))\n",
    "                if len(timestamp) >= th_timestamp or timestamp.startswith('1970'):\n",
    "                    print(\"Wrong timestamp: \" + timestamp)\n",
    "                if magn_z > th_sensor:\n",
    "                    print(\"Wrong sensor value: \" + str(magn_z))\n",
    "                print(\"\")\n",
    "        else:\n",
    "            writer.writerow(row)\n",
    "\n",
    "    inp.close()\n",
    "    out.close()\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    acc_input = open('sensoringData_acc.csv', 'r')\n",
    "    gyro_input = open('sensoringData_gyro.csv', 'r')\n",
    "    magn_input = open('sensoringData_magn.csv', 'r')\n",
    "    gps_input = open('sensoringData_gps.csv', 'r')\n",
    "\n",
    "    acc_output = open('sensoringData_acc_clean.csv', 'w', newline=\"\")\n",
    "    gyro_output = open('sensoringData_gyro_clean.csv', 'w', newline=\"\")\n",
    "    magn_output = open('sensoringData_magn_clean.csv', 'w', newline=\"\")\n",
    "    gps_output = open('sensoringData_gps_clean.csv', 'w', newline=\"\")\n",
    "\n",
    "    # 0.2, 0.2, 27, 2000, 500\n",
    "    anomaly_detection(acc_input, acc_output, float(sys.argv[1]), float(sys.argv[2]), int(sys.argv[3]), int(sys.argv[4]),\n",
    "                      float(sys.argv[5]), 'acc')\n",
    "    anomaly_detection(gyro_input, gyro_output, float(sys.argv[1]), float(sys.argv[2]), int(sys.argv[3]),\n",
    "                      int(sys.argv[4]), float(sys.argv[5]), 'gyro')\n",
    "    anomaly_detection(magn_input, magn_output, float(sys.argv[1]), float(sys.argv[2]), int(sys.argv[3]),\n",
    "                      int(sys.argv[4]), float(sys.argv[5]), 'magn')\n",
    "    anomaly_detection(gps_input, gps_output, float(sys.argv[1]), float(sys.argv[2]), int(sys.argv[3]), int(sys.argv[4]),\n",
    "                      float(sys.argv[5]), 'gps')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data_Adapter.py.\n",
    "This script cuts the first and final X seconds from each activity session. It also detects corrupted sessions,\n",
    "which are the ones that have gaps in the data related to all sensors but GPS (time gaps higher than five seconds).\n",
    "Also, replicates GPS data, in order to have at least one observation from this sensor in each sliding window.\n",
    "A validSessions file is also created to fasten feature extraction process by not evaluation sessions that did not record\n",
    "any GPS observation.\n",
    "Parameters:\n",
    "\t\t- Window size, in seconds (20).\n",
    "\t\t- Seconds to be cut from the first and final part of each session (5).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [4], line 177\u001B[0m\n\u001B[0;32m    172\u001B[0m     gps_adaptation(gps_input, gps_output, gps_writer, invalid_sess)\n\u001B[0;32m    175\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;18m__name__\u001B[39m \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m__main__\u001B[39m\u001B[38;5;124m'\u001B[39m:\n\u001B[0;32m    176\u001B[0m     \u001B[38;5;66;03m# 20, 5\u001B[39;00m\n\u001B[1;32m--> 177\u001B[0m     time_adapt_data(\u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margv\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m, \u001B[38;5;28mint\u001B[39m(sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m2\u001B[39m]))\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: '-f'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import sys\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def time_adapt_data(n_seconds, cut_seconds):\n",
    "    acc_input = open('sensoringData_acc_clean.csv', 'r')\n",
    "    gyro_input = open('sensoringData_gyro_clean.csv', 'r')\n",
    "    magn_input = open('sensoringData_magn_clean.csv', 'r')\n",
    "    gps_input = open('sensoringData_gps_clean.csv', 'r')\n",
    "\n",
    "    acc_output = open('sensoringData_acc_prepared_' + str(n_seconds) + '.csv', 'w', newline=\"\")\n",
    "    gyro_output = open('sensoringData_gyro_prepared_' + str(n_seconds) + '.csv', 'w', newline=\"\")\n",
    "    magn_output = open('sensoringData_magn_prepared_' + str(n_seconds) + '.csv', 'w', newline=\"\")\n",
    "    gps_output = open('sensoringData_gps_prepared_' + str(n_seconds) + '.csv', 'w', newline=\"\")\n",
    "\n",
    "    acc_writer = csv.writer(acc_output, delimiter=\",\")\n",
    "    gyro_writer = csv.writer(gyro_output, delimiter=\",\")\n",
    "    magn_writer = csv.writer(magn_output, delimiter=\",\")\n",
    "    gps_writer = csv.writer(gps_output, delimiter=\",\")\n",
    "\n",
    "    act_columns = ['id', 'user', 'init_timestamp', 'end_timestamp', 'activity_id', 'activity']\n",
    "    act_changes = pd.read_csv('activityChanges.csv', header=0, names=act_columns)\n",
    "\n",
    "    invalid_sess = []\n",
    "\n",
    "    def adaptation(input, output, writer, invalid_sess):\n",
    "        username = \"\"\n",
    "        activity_id = 0\n",
    "        timestamp = 0.0\n",
    "        timestamp_before = 0.0\n",
    "        ignore = False\n",
    "\n",
    "        for row in csv.reader(input):\n",
    "            if row[0] != \"id\":\n",
    "                username_now = row[1]\n",
    "                activity_id_now = row[6]\n",
    "                timestamp_now = float(row[2])\n",
    "                if username_now != username or activity_id_now != activity_id:\n",
    "                    username = row[1]\n",
    "                    activity_id = row[6]\n",
    "                    act_df = act_changes.loc[(act_changes['user'] == int(username)) &\n",
    "                                             (act_changes['activity_id'] == int(activity_id))]\n",
    "                    timestamp = act_df['init_timestamp'].values[0] + cut_seconds\n",
    "                    end_timestamp = act_df['end_timestamp'].values[0] - cut_seconds\n",
    "                    ignore = False\n",
    "                    for user_inv, act_inv in invalid_sess:\n",
    "                        if user_inv == username and act_inv == activity_id:\n",
    "                            ignore = True\n",
    "                    if not ignore:\n",
    "                        if timestamp_now > (timestamp + cut_seconds):\n",
    "                            ignore = True\n",
    "                            invalid_sess.append([username, activity_id])\n",
    "                    timestamp_before = timestamp_now\n",
    "                if end_timestamp >= timestamp_now >= timestamp and not ignore:\n",
    "                    if timestamp_now > (timestamp_before + cut_seconds):\n",
    "                        ignore = True\n",
    "                        invalid_sess.append([username, activity_id])\n",
    "                    else:\n",
    "                        writer.writerow(row)\n",
    "                timestamp_before = timestamp_now\n",
    "            else:\n",
    "                writer.writerow(row)\n",
    "\n",
    "        input.close()\n",
    "        output.close()\n",
    "\n",
    "        return invalid_sess\n",
    "\n",
    "    def gps_adaptation(input, output, writer, invalid_sess):\n",
    "        counter = -1\n",
    "        i = 0\n",
    "        username = \"\"\n",
    "        activity_id = 0\n",
    "        timestamp = 0.0\n",
    "        gps_seconds = 1\n",
    "        row_list = []\n",
    "        session_list = []\n",
    "        gps_values = []\n",
    "        ignore = False\n",
    "\n",
    "        for row in csv.reader(input):\n",
    "            if row[0] != \"id\":\n",
    "                username_now = row[1]\n",
    "                activity_id_now = row[9]\n",
    "                timestamp_now = float(row[2])\n",
    "                if username_now != username or activity_id_now != activity_id:\n",
    "                    if counter >= 0 and not ignore:\n",
    "                        for list_row in row_list:\n",
    "                            gps_values.append(list_row.copy())\n",
    "                            i += 1\n",
    "                        if counter == 0:\n",
    "                            timestamp_before = float(row_before[2])\n",
    "                            while timestamp_before >= (timestamp + gps_seconds):\n",
    "                                timestamp += gps_seconds\n",
    "                                last_row = row_list[len(row_list) - 1]\n",
    "                                aux_last_row = last_row.copy()\n",
    "                                if float(aux_last_row[2]) >= timestamp:\n",
    "                                    aux_last_row[2] = str(timestamp)\n",
    "                                    gps_values.insert(i - 1, aux_last_row.copy())\n",
    "                                    i += 1\n",
    "                        while end_timestamp >= (float(row_before[2]) + gps_seconds):\n",
    "                            aux_time = float(row_before[2]) + gps_seconds\n",
    "                            row_before[2] = aux_time\n",
    "                            gps_values.append(row_before.copy())\n",
    "                            i += 1\n",
    "                    username = row[1]\n",
    "                    activity_id = row[9]\n",
    "                    act_df = act_changes.loc[(act_changes['user'] == int(username)) &\n",
    "                                             (act_changes['activity_id'] == int(activity_id))]\n",
    "                    timestamp = act_df['init_timestamp'].values[0]\n",
    "                    end_timestamp = act_df['end_timestamp'].values[0]\n",
    "                    ignore = False\n",
    "                    for user_inv, act_inv in invalid_sess:\n",
    "                        if user_inv == username and act_inv == activity_id:\n",
    "                            ignore = True\n",
    "                    if not ignore:\n",
    "                        row_sess = [username, activity_id, timestamp, end_timestamp]\n",
    "                        if row_sess not in session_list:\n",
    "                            session_list.append(row_sess)\n",
    "                    counter = 0\n",
    "                    row_list.clear()\n",
    "                else:\n",
    "                    if timestamp_now >= (timestamp + gps_seconds) and not ignore:\n",
    "                        for list_row in row_list:\n",
    "                            gps_values.append(list_row.copy())\n",
    "                            i += 1\n",
    "                        while timestamp_now >= (timestamp + gps_seconds):\n",
    "                            timestamp += gps_seconds\n",
    "                            last_row = row_list[len(row_list) - 1]\n",
    "                            aux_last_row = last_row.copy()\n",
    "                            if counter == 0 and (float(aux_last_row[2]) >= timestamp):\n",
    "                                aux_last_row[2] = str(timestamp)\n",
    "                                gps_values.insert(i - 1, aux_last_row.copy())\n",
    "                                i += 1\n",
    "                            else:\n",
    "                                aux_last_row[2] = str(timestamp)\n",
    "                                gps_values.append(aux_last_row.copy())\n",
    "                                i += 1\n",
    "                        row_list.clear()\n",
    "                    counter += 1\n",
    "                row_list.append(row)\n",
    "                row_before = row\n",
    "            else:\n",
    "                writer.writerow(row)\n",
    "\n",
    "        if end_timestamp >= (float(row_before[2]) + gps_seconds) and not ignore:\n",
    "            for list_row in row_list:\n",
    "                gps_values.append(list_row.copy())\n",
    "            while end_timestamp >= (float(row_before[2]) + gps_seconds):\n",
    "                aux_time = float(row_before[2]) + gps_seconds\n",
    "                row_before[2] = aux_time\n",
    "                gps_values.append(row_before.copy())\n",
    "\n",
    "        session_output = open('validSessions_' + str(n_seconds) + '.csv', 'w', newline=\"\")\n",
    "        session_writer = csv.writer(session_output, delimiter=\",\")\n",
    "        session_row = ['username', 'activity_id', 'init_timestamp', 'end_timestamp']\n",
    "        session_writer.writerow(session_row)\n",
    "        for sess_row in session_list:\n",
    "            session_writer.writerow(sess_row)\n",
    "\n",
    "        writer.writerows(gps_values)\n",
    "\n",
    "        input.close()\n",
    "        output.close()\n",
    "        session_output.close()\n",
    "\n",
    "    invalid_sess = adaptation(acc_input, acc_output, acc_writer, invalid_sess)\n",
    "    invalid_sess = adaptation(gyro_input, gyro_output, gyro_writer, invalid_sess)\n",
    "    invalid_sess = adaptation(magn_input, magn_output, magn_writer, invalid_sess)\n",
    "    gps_adaptation(gps_input, gps_output, gps_writer, invalid_sess)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 20, 5\n",
    "    time_adapt_data(int(sys.argv[1]), int(sys.argv[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Data_Splitter.py\n",
    "Script used to split the data got from the previous script in X parts in order to fasten the feature extraction\n",
    "process.\n",
    "Parameters:\n",
    "\t\t- Window size used, in seconds (20).\n",
    "\t\t- Number of divisions to be applied (8).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def sensor_split(input, writers, row_count, last_act_ids, last_usernames, val_sess_df, is_gps):\n",
    "    counter = 0\n",
    "    row_counter = 0\n",
    "    username = \"\"\n",
    "    activity_id = 0\n",
    "    row_list = []\n",
    "    n_div = 0\n",
    "    writer_now = writers[0]\n",
    "    usernames = []\n",
    "    act_ids = []\n",
    "    invalid = False\n",
    "    last_valid_username = \"\"\n",
    "    last_valid_activity_id = 0\n",
    "\n",
    "    for row in csv.reader(input):\n",
    "        if row[0] != \"id\":\n",
    "            if counter == 0:\n",
    "                if row_count < 0:\n",
    "                    if username == last_usernames[n_div] and activity_id == last_act_ids[n_div]:\n",
    "                        row_counter = 0\n",
    "                        n_div += 1\n",
    "                        writer_now = writers[n_div]\n",
    "                else:\n",
    "                    if row_count <= row_counter:\n",
    "                        row_counter = 0\n",
    "                        n_div += 1\n",
    "                        writer_now = writers[n_div]\n",
    "                        if not invalid:\n",
    "                            usernames.append(username)\n",
    "                            act_ids.append(activity_id)\n",
    "                        else:\n",
    "                            usernames.append(last_valid_username)\n",
    "                            act_ids.append(last_valid_activity_id)\n",
    "                username = int(row[1])\n",
    "                if is_gps:\n",
    "                    activity_id = int(row[9])\n",
    "                else:\n",
    "                    activity_id = int(row[6])\n",
    "                sess_df = val_sess_df.loc[(val_sess_df['user'] == username) &\n",
    "                                          (val_sess_df['activity_id'] == activity_id)]\n",
    "                if len(sess_df) > 0:\n",
    "                    invalid = False\n",
    "                    last_valid_username = username\n",
    "                    last_valid_activity_id = activity_id\n",
    "                else:\n",
    "                    invalid = True\n",
    "            username_now = int(row[1])\n",
    "            if is_gps:\n",
    "                activity_id_now = int(row[9])\n",
    "            else:\n",
    "                activity_id_now = int(row[6])\n",
    "            if username_now != username or activity_id_now != activity_id:\n",
    "                if not invalid:\n",
    "                    for list_row in row_list:\n",
    "                        writer_now.writerow(list_row)\n",
    "                row_list.clear()\n",
    "                counter = 0\n",
    "            else:\n",
    "                counter += 1\n",
    "            row_list.append(row)\n",
    "            row_counter += 1\n",
    "        else:\n",
    "            for writer in writers:\n",
    "                writer.writerow(row)\n",
    "\n",
    "    if not invalid:\n",
    "        usernames.append(username)\n",
    "        act_ids.append(activity_id)\n",
    "    else:\n",
    "        usernames.append(last_valid_username)\n",
    "        act_ids.append(last_valid_activity_id)\n",
    "\n",
    "    return act_ids, usernames\n",
    "\n",
    "\n",
    "def split_data(n_seconds, n_div):\n",
    "    # We select gyroscope as the marker, as it is the most absent in every session.\n",
    "    input_gyro = open('sensoringData_gyro_prepared_' + str(n_seconds) + '.csv', 'r')\n",
    "    row_count_gyro = sum(1 for row in csv.reader(input_gyro))\n",
    "    row_count_gyro_div = row_count_gyro / n_div\n",
    "\n",
    "    val_sess_path = './validSessions_' + str(n_seconds) + '.csv'\n",
    "    val_sess_columns = ['user', 'activity_id', 'init_timestamp', 'end_timestamp']\n",
    "    val_sess_df = pd.read_csv(val_sess_path, header=0, names=val_sess_columns)\n",
    "    val_sess_df.head()\n",
    "\n",
    "    i = 1\n",
    "    writers_acc = []\n",
    "    writers_gyro = []\n",
    "    writers_magn = []\n",
    "    writers_gps = []\n",
    "    while i <= n_div:\n",
    "        writers_acc.append(csv.writer(open('sensoringData_acc_prepared_' + str(n_seconds) + '_' + str(i) + '.csv',\n",
    "                                      'w', newline=\"\"), delimiter=\",\"))\n",
    "        writers_gyro.append(csv.writer(open('sensoringData_gyro_prepared_' + str(n_seconds) + '_' + str(i) + '.csv',\n",
    "                                       'w', newline=\"\"), delimiter=\",\"))\n",
    "        writers_magn.append(csv.writer(open('sensoringData_magn_prepared_' + str(n_seconds) + '_' + str(i) + '.csv',\n",
    "                                       'w', newline=\"\"), delimiter=\",\"))\n",
    "        writers_gps.append(csv.writer(open('sensoringData_gps_prepared_' + str(n_seconds) + '_' + str(i) + '.csv',\n",
    "                                      'w', newline=\"\"), delimiter=\",\"))\n",
    "        i += 1\n",
    "\n",
    "    input_acc = open('sensoringData_acc_prepared_' + str(n_seconds) + '.csv', 'r')\n",
    "    input_gyro = open('sensoringData_gyro_prepared_' + str(n_seconds) + '.csv', 'r')\n",
    "    input_magn = open('sensoringData_magn_prepared_' + str(n_seconds) + '.csv', 'r')\n",
    "    input_gps = open('sensoringData_gps_prepared_' + str(n_seconds) + '.csv', 'r')\n",
    "\n",
    "    last_act_ids, last_usernames = sensor_split(input_gyro, writers_gyro, row_count_gyro_div, [], [], val_sess_df, False)\n",
    "    sensor_split(input_acc, writers_acc, -1, last_act_ids, last_usernames, val_sess_df, False)\n",
    "    sensor_split(input_magn, writers_magn, -1, last_act_ids, last_usernames, val_sess_df, False)\n",
    "    sensor_split(input_gps, writers_gps, -1, last_act_ids, last_usernames, val_sess_df, True)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    split_data(int(sys.argv[1]), int(sys.argv[2]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Feature_Extraction.py\n",
    "Here the feature computation for each window size is made.\n",
    "For each sliding window, we compute mean, var, mad, max, min and iqr functions over related data.\n",
    "This creates a file for each of the sets defined:\n",
    "\t\t0 - Acc + GPS (all users)\n",
    "\t\t1 - Acc + Magn + GPS (all users but the ones missing magnetometer)\n",
    "\t\t2 - Acc + Gyro + Magn + GPS (all users but the ones missing gyroscope and magnetometer)\n",
    "It is coded in a Slurm way to be executed as a job array (one job for every data split).\n",
    "Parameters:\n",
    "\t\t- Window size used, in seconds (20).\n",
    "\t\t- Overlap between windows, in seconds (19).\n",
    "\t\t- Number of seconds set to cut the first and final part of session (5).\n",
    "\t\t- Number of divisions applied over data (8).\n",
    "\t\t- Slurm job array index, from 1 to the number of divisions specified before (or -1 to join all data)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "from scipy import stats\n",
    "from astropy.stats import median_absolute_deviation\n",
    "\n",
    "\n",
    "# This does the main work, which is computing all the features and preparing the data lists to be file-written in the\n",
    "# next steps.\n",
    "def get_features(id, xs, ys, zs, speeds, bearings, accuracies, aux_count, aux_count_ng, aux_count_ngnm, data_2, data_1,\n",
    "                 data_0, user, timestamp, activity_id, activity, type):\n",
    "    xs_mean = np.mean(xs)\n",
    "    ys_mean = np.mean(ys)\n",
    "    zs_mean = np.mean(zs)\n",
    "    xs_var = np.var(xs)\n",
    "    ys_var = np.var(ys)\n",
    "    zs_var = np.var(zs)\n",
    "    xs_mad = median_absolute_deviation(xs)\n",
    "    ys_mad = median_absolute_deviation(ys)\n",
    "    zs_mad = median_absolute_deviation(zs)\n",
    "    xs_max = max(xs)\n",
    "    zs_max = max(zs)\n",
    "    ys_max = max(ys)\n",
    "    xs_min = min(xs)\n",
    "    ys_min = min(ys)\n",
    "    zs_min = min(zs)\n",
    "    xs_iqr = stats.iqr(xs, rng=(25, 75), interpolation='midpoint')\n",
    "    ys_iqr = stats.iqr(ys, rng=(25, 75), interpolation='midpoint')\n",
    "    zs_iqr = stats.iqr(zs, rng=(25, 75), interpolation='midpoint')\n",
    "\n",
    "    if type != 'gps':\n",
    "        if type == 'acc':\n",
    "            aux_count += 1\n",
    "            data_0.append(\n",
    "                [id, user, timestamp, xs_mean, ys_mean, zs_mean, xs_var, ys_var, zs_var, xs_mad, ys_mad, zs_mad, xs_max,\n",
    "                 ys_max, zs_max, xs_min, ys_min, zs_min, xs_iqr, ys_iqr, zs_iqr])\n",
    "            if user != 14 and user != 18:\n",
    "                aux_count_ng += 1\n",
    "                data_1.append(\n",
    "                    [id, user, timestamp, xs_mean, ys_mean, zs_mean, xs_var, ys_var, zs_var, xs_mad, ys_mad, zs_mad,\n",
    "                     xs_max, ys_max, zs_max, xs_min, ys_min, zs_min, xs_iqr, ys_iqr, zs_iqr])\n",
    "                if user != 4 and user != 15 and user != 17:\n",
    "                    aux_count_ngnm += 1\n",
    "                    data_2.append(\n",
    "                        [id, user, timestamp, xs_mean, ys_mean, zs_mean, xs_var, ys_var, zs_var, xs_mad, ys_mad, zs_mad,\n",
    "                         xs_max, ys_max, zs_max, xs_min, ys_min, zs_min, xs_iqr, ys_iqr, zs_iqr])\n",
    "        else:\n",
    "            aux_count += 1\n",
    "            data_0.append(\n",
    "                [xs_mean, ys_mean, zs_mean, xs_var, ys_var, zs_var, xs_mad, ys_mad, zs_mad, xs_max, ys_max, zs_max,\n",
    "                 xs_min, ys_min, zs_min, xs_iqr, ys_iqr, zs_iqr])\n",
    "            if user != 14 and user != 18:\n",
    "                aux_count_ng += 1\n",
    "                data_1.append(\n",
    "                    [xs_mean, ys_mean, zs_mean, xs_var, ys_var, zs_var, xs_mad, ys_mad, zs_mad, xs_max, ys_max, zs_max,\n",
    "                     xs_min, ys_min, zs_min, xs_iqr, ys_iqr, zs_iqr])\n",
    "                if user != 4 and user != 15 and user != 17:\n",
    "                    aux_count_ngnm += 1\n",
    "                    data_2.append(\n",
    "                        [xs_mean, ys_mean, zs_mean, xs_var, ys_var, zs_var, xs_mad, ys_mad, zs_mad, xs_max, ys_max,\n",
    "                         zs_max, xs_min, ys_min, zs_min, xs_iqr, ys_iqr, zs_iqr])\n",
    "    else:\n",
    "        speeds_mean = np.mean(speeds)\n",
    "        bearings_mean = np.mean(bearings)\n",
    "        accuracies_mean = np.mean(accuracies)\n",
    "        speeds_var = np.var(speeds)\n",
    "        bearings_var = np.var(bearings)\n",
    "        accuracies_var = np.var(accuracies)\n",
    "        speeds_mad = median_absolute_deviation(speeds)\n",
    "        bearings_mad = median_absolute_deviation(bearings)\n",
    "        accuracies_mad = median_absolute_deviation(accuracies)\n",
    "        speeds_max = max(speeds)\n",
    "        bearings_max = max(bearings)\n",
    "        accuracies_max = max(accuracies)\n",
    "        speeds_min = min(speeds)\n",
    "        bearings_min = min(bearings)\n",
    "        accuracies_min = min(accuracies)\n",
    "        speeds_iqr = stats.iqr(speeds, rng=(25, 75), interpolation='midpoint')\n",
    "        bearings_iqr = stats.iqr(bearings, rng=(25, 75), interpolation='midpoint')\n",
    "        accuracies_iqr = stats.iqr(accuracies, rng=(25, 75), interpolation='midpoint')\n",
    "\n",
    "        aux_count += 1\n",
    "        data_0.append(\n",
    "            [xs_mean, ys_mean, zs_mean, speeds_mean, bearings_mean, accuracies_mean, xs_var, ys_var, zs_var, speeds_var,\n",
    "             bearings_var, accuracies_var, xs_mad, ys_mad, zs_mad, speeds_mad, bearings_mad, accuracies_mad, xs_max,\n",
    "             ys_max, zs_max, speeds_max, bearings_max, accuracies_max, xs_min, ys_min, zs_min, speeds_min, bearings_min,\n",
    "             accuracies_min, xs_iqr, ys_iqr, zs_iqr, speeds_iqr, bearings_iqr, accuracies_iqr, activity_id, activity])\n",
    "        if user != 14 and user != 18:\n",
    "            aux_count_ng += 1\n",
    "            data_1.append(\n",
    "                [xs_mean, ys_mean, zs_mean, speeds_mean, bearings_mean, accuracies_mean, xs_var, ys_var, zs_var,\n",
    "                 speeds_var, bearings_var, accuracies_var, xs_mad, ys_mad, zs_mad, speeds_mad, bearings_mad,\n",
    "                 accuracies_mad, xs_max, ys_max, zs_max, speeds_max, bearings_max, accuracies_max, xs_min, ys_min,\n",
    "                 zs_min, speeds_min, bearings_min, accuracies_min, xs_iqr, ys_iqr, zs_iqr, speeds_iqr, bearings_iqr,\n",
    "                 accuracies_iqr, activity_id, activity])\n",
    "            if user != 4 and user != 15 and user != 17:\n",
    "                aux_count_ngnm += 1\n",
    "                data_2.append(\n",
    "                    [xs_mean, ys_mean, zs_mean, speeds_mean, bearings_mean, accuracies_mean, xs_var, ys_var, zs_var,\n",
    "                     speeds_var, bearings_var, accuracies_var, xs_mad, ys_mad, zs_mad, speeds_mad, bearings_mad,\n",
    "                     accuracies_mad, xs_max, ys_max, zs_max, speeds_max, bearings_max, accuracies_max, xs_min, ys_min,\n",
    "                     zs_min, speeds_min, bearings_min, accuracies_min, xs_iqr, ys_iqr, zs_iqr, speeds_iqr, bearings_iqr,\n",
    "                     accuracies_iqr, activity_id, activity])\n",
    "\n",
    "    return data_2, data_1, data_0, aux_count, aux_count_ng, aux_count_ngnm\n",
    "\n",
    "\n",
    "# All the logic regarding the correct application of each sliding window and feature computation.\n",
    "def extraction(df, type, n_seconds, overlap, cut_seconds, val_sess_df):\n",
    "    i = 1\n",
    "    next_i = 0\n",
    "    init = False\n",
    "    init_out = False\n",
    "    finish_window = False\n",
    "    stop_count = False\n",
    "    data_0 = []\n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "    aux_count_ngnm = 0\n",
    "    aux_count_ng = 0\n",
    "    aux_count = 0\n",
    "    aux_data_ngnm = []\n",
    "    aux_data_ng = []\n",
    "    aux_data = []\n",
    "    xs = []\n",
    "    ys = []\n",
    "    zs = []\n",
    "    speeds = []\n",
    "    bearings = []\n",
    "    accuracies = []\n",
    "    timestamp_list = []\n",
    "    x_value = ''\n",
    "    y_value = ''\n",
    "    z_value = ''\n",
    "    s_value = ''\n",
    "    b_value = ''\n",
    "    a_value = ''\n",
    "    timestamp = 0\n",
    "    timestamp_beginning = 0\n",
    "    timestamp_before = 0\n",
    "    end_timestamp = 0\n",
    "    user_beginning = ''\n",
    "    next_time = 0\n",
    "    if type == 'acc':\n",
    "        x_value = 'acc_x_axis'\n",
    "        y_value = 'acc_y_axis'\n",
    "        z_value = 'acc_z_axis'\n",
    "    else:\n",
    "        if type == 'gyro':\n",
    "            x_value = 'gyro_x_axis'\n",
    "            y_value = 'gyro_y_axis'\n",
    "            z_value = 'gyro_z_axis'\n",
    "        else:\n",
    "            if type == 'magn':\n",
    "                x_value = 'magn_x_axis'\n",
    "                y_value = 'magn_y_axis'\n",
    "                z_value = 'magn_z_axis'\n",
    "            else:\n",
    "                if type == 'gps':\n",
    "                    x_value = 'gps_lat_increment'\n",
    "                    y_value = 'gps_long_increment'\n",
    "                    z_value = 'gps_alt_increment'\n",
    "                    s_value = 'gps_speed'\n",
    "                    b_value = 'gps_bearing'\n",
    "                    a_value = 'gps_accuracy'\n",
    "\n",
    "    while i < len(df):\n",
    "        i_before = i\n",
    "        id = df['id'].values[i]\n",
    "        user = df['user'].values[i]\n",
    "        timestamp = float(df['timestamp'].values[i])\n",
    "        activity_id = df['activity_id'].values[i]\n",
    "        activity = df['activity'].values[i]\n",
    "        sess_df = val_sess_df.loc[(val_sess_df['user'] == int(user)) & (val_sess_df['activity_id'] == int(activity_id))]\n",
    "        if len(sess_df) > 0:\n",
    "            invalid = False\n",
    "        else:\n",
    "            invalid = True\n",
    "\n",
    "        if not init and not invalid:\n",
    "            timestamp_beginning = sess_df['init_timestamp'].values[0] + cut_seconds\n",
    "            end_timestamp = sess_df['end_timestamp'].values[0] - cut_seconds\n",
    "            next_time = timestamp_beginning + (n_seconds - overlap)\n",
    "            user_beginning = user\n",
    "            activity_id_beginning = activity_id\n",
    "            activity_beginning = activity\n",
    "            init = True\n",
    "            if i > 1:\n",
    "                init_out = True\n",
    "\n",
    "        if init_out or ((user_beginning != user or activity_id_beginning != activity_id\n",
    "                         or activity_beginning != activity) and not invalid):\n",
    "            if timestamp_before <= (timestamp_beginning + n_seconds) <= end_timestamp and len(xs) > 0:\n",
    "                data_2, data_1, data_0, aux_count, aux_count_ng, aux_count_ngnm = get_features(id, xs, ys, zs, speeds,\n",
    "                    bearings, accuracies, aux_count, aux_count_ng, aux_count_ngnm, data_2, data_1, data_0,\n",
    "                    user_beginning, timestamp_before, activity_id_beginning, activity_beginning, type)\n",
    "\n",
    "            if aux_count > 0:\n",
    "                aux_data.append([activity_id_beginning, aux_count])\n",
    "            if aux_count_ng > 0:\n",
    "                aux_data_ng.append([activity_id_beginning, aux_count_ng])\n",
    "            if aux_count_ngnm > 0:\n",
    "                aux_data_ngnm.append([activity_id_beginning, aux_count_ngnm])\n",
    "            aux_count = 0\n",
    "            aux_count_ng = 0\n",
    "            aux_count_ngnm = 0\n",
    "            timestamp_beginning = sess_df['init_timestamp'].values[0] + cut_seconds\n",
    "            end_timestamp = sess_df['end_timestamp'].values[0] - cut_seconds\n",
    "            next_time = timestamp_beginning + (n_seconds - overlap)\n",
    "            user_beginning = user\n",
    "            activity_id_beginning = activity_id\n",
    "            activity_beginning = activity\n",
    "            xs = []\n",
    "            ys = []\n",
    "            zs = []\n",
    "            speeds = []\n",
    "            bearings = []\n",
    "            accuracies = []\n",
    "            timestamp_list = []\n",
    "            init_out = False\n",
    "            stop_count = False\n",
    "            i += 1\n",
    "        else:\n",
    "            if timestamp >= next_time and not stop_count and not invalid:\n",
    "                next_i = i\n",
    "                stop_count = True\n",
    "            if end_timestamp >= timestamp >= timestamp_beginning + n_seconds and not invalid:\n",
    "                if not xs:\n",
    "                    print(\"timestamp: \" + str(timestamp))\n",
    "                    print(\"timestamp_beginning: \" + str(timestamp_beginning))\n",
    "                    print(\"timestamp_before: \" + str(timestamp_before))\n",
    "                    print(\"end_timestamp: \" + str(end_timestamp))\n",
    "                    print(\"activity_id: \" + str(activity_id))\n",
    "                    print(\"user: \" + str(user))\n",
    "                    print(\"next_i: \" + str(next_i))\n",
    "                    print(\"next_time: \" + str(next_time))\n",
    "                    print(\"i: \" + str(i))\n",
    "                    print(\"type: \" + str(type))\n",
    "                data_2, data_1, data_0, aux_count, aux_count_ng, aux_count_ngnm = get_features(id, xs, ys, zs, speeds,\n",
    "                    bearings, accuracies, aux_count, aux_count_ng, aux_count_ngnm, data_2, data_1, data_0, user,\n",
    "                    timestamp, activity_id, activity, type)\n",
    "\n",
    "                timestamp_beginning = next_time\n",
    "                next_time = timestamp_beginning + (n_seconds - overlap)\n",
    "                xs = []\n",
    "                ys = []\n",
    "                zs = []\n",
    "                speeds = []\n",
    "                bearings = []\n",
    "                accuracies = []\n",
    "                timestamp_list = []\n",
    "\n",
    "                user = df['user'].values[i]\n",
    "                timestamp = float(df['timestamp'].values[i])\n",
    "                activity_id = df['activity_id'].values[i]\n",
    "                activity = df['activity'].values[i]\n",
    "                if next_i < i:\n",
    "                    if (df['user'].values[next_i] == user) and (df['activity_id'].values[next_i] == activity_id) and (\n",
    "                            df['activity'].values[next_i] == activity):\n",
    "                        i = next_i\n",
    "                    else:\n",
    "                        i += 1\n",
    "                else:\n",
    "                    i += 1\n",
    "                stop_count = False\n",
    "                finish_window = True\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        if not finish_window and not invalid and (end_timestamp >= timestamp >= timestamp_beginning):\n",
    "            xs.append(df[x_value].values[i_before])\n",
    "            ys.append(df[y_value].values[i_before])\n",
    "            zs.append(df[z_value].values[i_before])\n",
    "            if type == 'gps':\n",
    "                speeds.append(df[s_value].values[i_before])\n",
    "                bearings.append(df[b_value].values[i_before])\n",
    "                accuracies.append(df[a_value].values[i_before])\n",
    "            timestamp_list.append(float(df['timestamp'].values[i_before]))\n",
    "        timestamp_before = timestamp\n",
    "        finish_window = False\n",
    "\n",
    "    if timestamp_before <= (timestamp_beginning + n_seconds) <= end_timestamp and not invalid and len(xs) > 0:\n",
    "        data_2, data_1, data_0, aux_count, aux_count_ng, aux_count_ngnm = get_features(id, xs, ys, zs, speeds, bearings,\n",
    "            accuracies, aux_count, aux_count_ng, aux_count_ngnm, data_2, data_1, data_0, user_beginning,\n",
    "            timestamp_before, activity_id_beginning, activity_beginning, type)\n",
    "\n",
    "    if aux_count > 0:\n",
    "        aux_data.append([activity_id_beginning, aux_count])\n",
    "    if aux_count_ng > 0:\n",
    "        aux_data_ng.append([activity_id_beginning, aux_count_ng])\n",
    "    if aux_count_ngnm > 0:\n",
    "        aux_data_ngnm.append([activity_id_beginning, aux_count_ngnm])\n",
    "    return data_2, data_1, data_0, aux_data_ngnm, aux_data_ng, aux_data\n",
    "\n",
    "\n",
    "# Function to initialize and finish all the computation process. It does some calculus in the end to make sure that each\n",
    "# sensor has the same number of computed windows, getting rid of possible limit situations.\n",
    "def process_data_split(n_div, n_seconds, overlap, cut_seconds):\n",
    "    acc_path = './sensoringData_acc_prepared_' + str(n_seconds) + '_' + str(n_div) + '.csv'\n",
    "    gyro_path = './sensoringData_gyro_prepared_' + str(n_seconds) + '_' + str(n_div) + '.csv'\n",
    "    magn_path = './sensoringData_magn_prepared_' + str(n_seconds) + '_' + str(n_div) + '.csv'\n",
    "    gps_path = './sensoringData_gps_prepared_' + str(n_seconds) + '_' + str(n_div) + '.csv'\n",
    "    val_sess_path = './validSessions_' + str(n_seconds) + '.csv'\n",
    "\n",
    "    acc_columns = ['id', 'user', 'timestamp', 'acc_x_axis', 'acc_y_axis', 'acc_z_axis', 'activity_id', 'activity']\n",
    "    gyro_columns = ['id', 'user', 'timestamp', 'gyro_x_axis', 'gyro_y_axis', 'gyro_z_axis', 'activity_id', 'activity']\n",
    "    magn_columns = ['id', 'user', 'timestamp', 'magn_x_axis', 'magn_y_axis', 'magn_z_axis', 'activity_id', 'activity']\n",
    "    gps_columns = ['id', 'user', 'timestamp', 'gps_lat_increment', 'gps_long_increment', 'gps_alt_increment',\n",
    "                   'gps_speed', 'gps_bearing', 'gps_accuracy', 'activity_id', 'activity']\n",
    "    val_sess_columns = ['user', 'activity_id', 'init_timestamp', 'end_timestamp']\n",
    "    acc_df = pd.read_csv(acc_path, header=0, names=acc_columns)\n",
    "    acc_df.head()\n",
    "    gyro_df = pd.read_csv(gyro_path, header=0, names=gyro_columns)\n",
    "    gyro_df.head()\n",
    "    magn_df = pd.read_csv(magn_path, header=0, names=magn_columns)\n",
    "    magn_df.head()\n",
    "    gps_df = pd.read_csv(gps_path, header=0, names=gps_columns)\n",
    "    gps_df.head()\n",
    "    val_sess_df = pd.read_csv(val_sess_path, header=0, names=val_sess_columns)\n",
    "    val_sess_df.head()\n",
    "\n",
    "    data_0 = []\n",
    "    data_1 = []\n",
    "    data_2 = []\n",
    "\n",
    "    results = []\n",
    "    sensors = [[acc_df, 'acc'], [gyro_df, 'gyro'], [magn_df, 'magn'], [gps_df, 'gps']]\n",
    "    for sensor in sensors:\n",
    "        ext_results = extraction(sensor[0], sensor[1], n_seconds, overlap, cut_seconds, val_sess_df)\n",
    "        results.append(ext_results)\n",
    "\n",
    "    acc_data_2, acc_data_1, acc_data_0, aux_acc_ngnm, aux_acc_ng, aux_acc = results[0]\n",
    "    gyro_data_2, gyro_data_1, gyro_data_0, aux_gyro_ngnm, aux_gyro_ng, aux_gyro = results[1]\n",
    "    magn_data_2, magn_data_1, magn_data_0, aux_magn_ngnm, aux_magn_ng, aux_magn = results[2]\n",
    "    gps_data_2, gps_data_1, gps_data_0, aux_gps_ngnm, aux_gps_ng, aux_gps = results[3]\n",
    "\n",
    "    l12 = len(acc_data_2)\n",
    "    l22 = len(gyro_data_2)\n",
    "    l32 = len(magn_data_2)\n",
    "    l42 = len(gps_data_2)\n",
    "    l11 = len(acc_data_1)\n",
    "    l31 = len(magn_data_1)\n",
    "    l41 = len(gps_data_1)\n",
    "    l10 = len(acc_data_0)\n",
    "    l40 = len(gps_data_0)\n",
    "    print(str(l12))\n",
    "    print(str(l22))\n",
    "    print(str(l32))\n",
    "    print(str(l42))\n",
    "    print(str(l11))\n",
    "    print(str(l31))\n",
    "    print(str(l41))\n",
    "    print(str(l10))\n",
    "    print(str(l40))\n",
    "\n",
    "    if l12 != l22 or l12 != l32 or l12 != l42 or l22 != l32 or l22 != l42 or l32 != l42:\n",
    "        z = 0\n",
    "        acc_val = 0\n",
    "        minLen = min(len(aux_acc_ngnm), len(aux_gyro_ngnm), len(aux_magn_ngnm), len(aux_gps_ngnm))\n",
    "        while z < minLen:\n",
    "            min_val = min(aux_acc_ngnm[z][1], aux_gyro_ngnm[z][1], aux_magn_ngnm[z][1], aux_gps_ngnm[z][1])\n",
    "            if aux_acc_ngnm[z][1] != aux_gyro_ngnm[z][1] or aux_acc_ngnm[z][1] != aux_magn_ngnm[z][1] or \\\n",
    "                    aux_acc_ngnm[z][1] != aux_gps_ngnm[z][1]:\n",
    "                if min_val == aux_acc_ngnm[z][1]:\n",
    "                    gyro_del = aux_gyro_ngnm[z][1] - min_val\n",
    "                    k = 0\n",
    "                    while k < gyro_del:\n",
    "                        gyro_data_2.pop(acc_val + min_val)\n",
    "                        k += 1\n",
    "                    magn_del = aux_magn_ngnm[z][1] - min_val\n",
    "                    k = 0\n",
    "                    while k < magn_del:\n",
    "                        magn_data_2.pop(acc_val + min_val)\n",
    "                        k += 1\n",
    "                    gps_del = aux_gps_ngnm[z][1] - min_val\n",
    "                    k = 0\n",
    "                    while k < gps_del:\n",
    "                        gps_data_2.pop(acc_val + min_val)\n",
    "                        k += 1\n",
    "                else:\n",
    "                    if min_val == aux_gyro_ngnm[z][1]:\n",
    "                        acc_del = aux_acc_ngnm[z][1] - min_val\n",
    "                        k = 0\n",
    "                        while k < acc_del:\n",
    "                            acc_data_2.pop(acc_val + min_val)\n",
    "                            k += 1\n",
    "                        magn_del = aux_magn_ngnm[z][1] - min_val\n",
    "                        k = 0\n",
    "                        while k < magn_del:\n",
    "                            magn_data_2.pop(acc_val + min_val)\n",
    "                            k += 1\n",
    "                        gps_del = aux_gps_ngnm[z][1] - min_val\n",
    "                        k = 0\n",
    "                        while k < gps_del:\n",
    "                            gps_data_2.pop(acc_val + min_val)\n",
    "                            k += 1\n",
    "                    else:\n",
    "                        if min_val == aux_magn_ngnm[z][1]:\n",
    "                            acc_del = aux_acc_ngnm[z][1] - min_val\n",
    "                            k = 0\n",
    "                            while k < acc_del:\n",
    "                                acc_data_2.pop(acc_val + min_val)\n",
    "                                k += 1\n",
    "                            gyro_del = aux_gyro_ngnm[z][1] - min_val\n",
    "                            k = 0\n",
    "                            while k < gyro_del:\n",
    "                                gyro_data_2.pop(acc_val + min_val)\n",
    "                                k += 1\n",
    "                            gps_del = aux_gps_ngnm[z][1] - min_val\n",
    "                            k = 0\n",
    "                            while k < gps_del:\n",
    "                                gps_data_2.pop(acc_val + min_val)\n",
    "                                k += 1\n",
    "                        else:\n",
    "                            if min_val == aux_gps_ngnm[z][1]:\n",
    "                                acc_del = aux_acc_ngnm[z][1] - min_val\n",
    "                                k = 0\n",
    "                                while k < acc_del:\n",
    "                                    acc_data_2.pop(acc_val + min_val)\n",
    "                                    k += 1\n",
    "                                gyro_del = aux_gyro_ngnm[z][1] - min_val\n",
    "                                k = 0\n",
    "                                while k < gyro_del:\n",
    "                                    gyro_data_2.pop(acc_val + min_val)\n",
    "                                    k += 1\n",
    "                                magn_del = aux_magn_ngnm[z][1] - min_val\n",
    "                                k = 0\n",
    "                                while k < magn_del:\n",
    "                                    magn_data_2.pop(acc_val + min_val)\n",
    "                                    k += 1\n",
    "            acc_val += min_val\n",
    "            z += 1\n",
    "\n",
    "    if l11 != l31 or l11 != l41 or l31 != l41:\n",
    "        z = 0\n",
    "        acc_val = 0\n",
    "        minLen = min(len(aux_acc_ng), len(aux_magn_ng), len(aux_gps_ng))\n",
    "        while z < minLen:\n",
    "            min_val = min(aux_acc_ng[z][1], aux_magn_ng[z][1], aux_gps_ng[z][1])\n",
    "            if aux_acc_ng[z][1] != aux_magn_ng[z][1] or aux_acc_ng[z][1] != aux_gps_ng[z][1]:\n",
    "                if min_val == aux_acc_ng[z][1]:\n",
    "                    magn_del = aux_magn_ng[z][1] - min_val\n",
    "                    k = 0\n",
    "                    while k < magn_del:\n",
    "                        magn_data_1.pop(acc_val + min_val)\n",
    "                        k += 1\n",
    "                    gps_del = aux_gps_ng[z][1] - min_val\n",
    "                    k = 0\n",
    "                    while k < gps_del:\n",
    "                        gps_data_1.pop(acc_val + min_val)\n",
    "                        k += 1\n",
    "                else:\n",
    "                    if min_val == aux_magn_ng[z][1]:\n",
    "                        acc_del = aux_acc_ng[z][1] - min_val\n",
    "                        k = 0\n",
    "                        while k < acc_del:\n",
    "                            acc_data_1.pop(acc_val + min_val)\n",
    "                            k += 1\n",
    "                        gps_del = aux_gps_ng[z][1] - min_val\n",
    "                        k = 0\n",
    "                        while k < gps_del:\n",
    "                            gps_data_1.pop(acc_val + min_val)\n",
    "                            k += 1\n",
    "                    else:\n",
    "                        if min_val == aux_gps_ng[z][1]:\n",
    "                            acc_del = aux_acc_ng[z][1] - min_val\n",
    "                            k = 0\n",
    "                            while k < acc_del:\n",
    "                                acc_data_1.pop(acc_val + min_val)\n",
    "                                k += 1\n",
    "                            magn_del = aux_magn_ng[z][1] - min_val\n",
    "                            k = 0\n",
    "                            while k < magn_del:\n",
    "                                magn_data_1.pop(acc_val + min_val)\n",
    "                                k += 1\n",
    "            acc_val += min_val\n",
    "            z += 1\n",
    "\n",
    "    if l10 != l40:\n",
    "        z = 0\n",
    "        acc_val = 0\n",
    "        minLen = min(len(aux_acc), len(aux_gps))\n",
    "        while z < minLen:\n",
    "            min_val = min(aux_acc[z][1], aux_gps[z][1])\n",
    "            if aux_acc[z][1] != aux_gps[z][1]:\n",
    "                if min_val == aux_acc[z][1]:\n",
    "                    gps_del = aux_gps[z][1] - min_val\n",
    "                    k = 0\n",
    "                    while k < gps_del:\n",
    "                        gps_data_0.pop(acc_val + min_val)\n",
    "                        k += 1\n",
    "                else:\n",
    "                    if min_val == aux_gps[z][1]:\n",
    "                        acc_del = aux_acc[z][1] - min_val\n",
    "                        k = 0\n",
    "                        while k < acc_del:\n",
    "                            acc_data_0.pop(acc_val + min_val)\n",
    "                            k += 1\n",
    "            acc_val += min_val\n",
    "            z += 1\n",
    "\n",
    "    j = 0\n",
    "    minDataLen = min(len(acc_data_2), len(gyro_data_2), len(magn_data_2), len(gps_data_2))\n",
    "    while j < minDataLen:\n",
    "        data_2.append(acc_data_2[j] + gyro_data_2[j] + magn_data_2[j] + gps_data_2[j])\n",
    "        j += 1\n",
    "    j = 0\n",
    "    minDataLen = min(len(acc_data_1), len(magn_data_1), len(gps_data_1))\n",
    "    while j < minDataLen:\n",
    "        data_1.append(acc_data_1[j] + magn_data_1[j] + gps_data_1[j])\n",
    "        j += 1\n",
    "    j = 0\n",
    "    minDataLen = min(len(acc_data_0), len(gps_data_0))\n",
    "    while j < minDataLen:\n",
    "        data_0.append(acc_data_0[j] + gps_data_0[j])\n",
    "        j += 1\n",
    "\n",
    "    filePath = './'\n",
    "    fileName_0 = 'sensoringData_feature_prepared_' + str(n_seconds) + '_' + str(overlap) + '_0_split_' + str(n_div) \\\n",
    "                 + '.csv'\n",
    "    fileName_1 = 'sensoringData_feature_prepared_' + str(n_seconds) + '_' + str(overlap) + '_1_split_' + str(n_div) \\\n",
    "                 + '.csv'\n",
    "    fileName_2 = 'sensoringData_feature_prepared_' + str(n_seconds) + '_' + str(overlap) + '_2_split_' + str(n_div) \\\n",
    "                 + '.csv'\n",
    "\n",
    "    # Extract the table headers.\n",
    "    headers_2 = ['id', 'user', 'timestamp', 'acc_xs_mean', 'acc_ys_mean', 'acc_zs_mean', 'acc_xs_var', 'acc_ys_var',\n",
    "                 'acc_zs_var', 'acc_xs_mad', 'acc_ys_mad', 'acc_zs_mad', 'acc_xs_max', 'acc_ys_max', 'acc_zs_max',\n",
    "                 'acc_xs_min', 'acc_ys_min', 'acc_zs_min', 'acc_xs_iqr', 'acc_ys_iqr', 'acc_zs_iqr', 'gyro_xs_mean',\n",
    "                 'gyro_ys_mean', 'gyro_zs_mean', 'gyro_xs_var', 'gyro_ys_var', 'gyro_zs_var', 'gyro_xs_mad',\n",
    "                 'gyro_ys_mad', 'gyro_zs_mad', 'gyro_xs_max', 'gyro_ys_max', 'gyro_zs_max', 'gyro_xs_min',\n",
    "                 'gyro_ys_min', 'gyro_zs_min', 'gyro_xs_iqr', 'gyro_ys_iqr', 'gyro_zs_iqr', 'magn_xs_mean',\n",
    "                 'magn_ys_mean', 'magn_zs_mean', 'magn_xs_var', 'magn_ys_var', 'magn_zs_var', 'magn_xs_mad',\n",
    "                 'magn_ys_mad', 'magn_zs_mad', 'magn_xs_max', 'magn_ys_max', 'magn_zs_max', 'magn_xs_min',\n",
    "                 'magn_ys_min', 'magn_zs_min', 'magn_xs_iqr', 'magn_ys_iqr', 'magn_zs_iqr', 'gps_lat_mean',\n",
    "                 'gps_long_mean', 'gps_alt_mean', 'gps_speed_mean', 'gps_bearing_mean', 'gps_accuracy_mean',\n",
    "                 'gps_lat_var', 'gps_long_var', 'gps_alt_var', 'gps_speed_var', 'gps_bearing_var', 'gps_accuracy_var',\n",
    "                 'gps_lat_mad', 'gps_long_mad', 'gps_alt_mad', 'gps_speed_mad', 'gps_bearing_mad', 'gps_accuracy_mad',\n",
    "                 'gps_lat_max', 'gps_long_max', 'gps_alt_max', 'gps_speed_max', 'gps_bearing_max', 'gps_accuracy_max',\n",
    "                 'gps_lat_min', 'gps_long_min', 'gps_alt_min', 'gps_speed_min', 'gps_bearing_min', 'gps_accuracy_min',\n",
    "                 'gps_lat_iqr', 'gps_long_iqr', 'gps_alt_iqr', 'gps_speed_iqr', 'gps_bearing_iqr', 'gps_accuracy_iqr',\n",
    "                 'activity_id', 'activity']\n",
    "\n",
    "    headers_1 = ['id', 'user', 'timestamp', 'acc_xs_mean', 'acc_ys_mean', 'acc_zs_mean', 'acc_xs_var', 'acc_ys_var',\n",
    "                 'acc_zs_var', 'acc_xs_mad', 'acc_ys_mad', 'acc_zs_mad', 'acc_xs_max', 'acc_ys_max', 'acc_zs_max',\n",
    "                 'acc_xs_min', 'acc_ys_min', 'acc_zs_min', 'acc_xs_iqr', 'acc_ys_iqr', 'acc_zs_iqr', 'magn_xs_mean',\n",
    "                 'magn_ys_mean', 'magn_zs_mean', 'magn_xs_var', 'magn_ys_var', 'magn_zs_var', 'magn_xs_mad',\n",
    "                 'magn_ys_mad', 'magn_zs_mad', 'magn_xs_max', 'magn_ys_max', 'magn_zs_max', 'magn_xs_min',\n",
    "                 'magn_ys_min', 'magn_zs_min', 'magn_xs_iqr', 'magn_ys_iqr', 'magn_zs_iqr', 'gps_lat_mean',\n",
    "                 'gps_long_mean', 'gps_alt_mean', 'gps_speed_mean', 'gps_bearing_mean', 'gps_accuracy_mean',\n",
    "                 'gps_lat_var', 'gps_long_var', 'gps_alt_var', 'gps_speed_var', 'gps_bearing_var', 'gps_accuracy_var',\n",
    "                 'gps_lat_mad', 'gps_long_mad', 'gps_alt_mad', 'gps_speed_mad', 'gps_bearing_mad', 'gps_accuracy_mad',\n",
    "                 'gps_lat_max', 'gps_long_max', 'gps_alt_max', 'gps_speed_max', 'gps_bearing_max', 'gps_accuracy_max',\n",
    "                 'gps_lat_min', 'gps_long_min', 'gps_alt_min', 'gps_speed_min', 'gps_bearing_min', 'gps_accuracy_min',\n",
    "                 'gps_lat_iqr', 'gps_long_iqr', 'gps_alt_iqr', 'gps_speed_iqr', 'gps_bearing_iqr', 'gps_accuracy_iqr',\n",
    "                 'activity_id', 'activity']\n",
    "\n",
    "    headers_0 = ['id', 'user', 'timestamp', 'acc_xs_mean', 'acc_ys_mean', 'acc_zs_mean', 'acc_xs_var', 'acc_ys_var',\n",
    "                 'acc_zs_var', 'acc_xs_mad', 'acc_ys_mad', 'acc_zs_mad', 'acc_xs_max', 'acc_ys_max', 'acc_zs_max',\n",
    "                 'acc_xs_min', 'acc_ys_min', 'acc_zs_min', 'acc_xs_iqr', 'acc_ys_iqr', 'acc_zs_iqr', 'gps_lat_mean',\n",
    "                 'gps_long_mean', 'gps_alt_mean', 'gps_speed_mean', 'gps_bearing_mean', 'gps_accuracy_mean',\n",
    "                 'gps_lat_var', 'gps_long_var', 'gps_alt_var', 'gps_speed_var', 'gps_bearing_var', 'gps_accuracy_var',\n",
    "                 'gps_lat_mad', 'gps_long_mad', 'gps_alt_mad', 'gps_speed_mad', 'gps_bearing_mad', 'gps_accuracy_mad',\n",
    "                 'gps_lat_max', 'gps_long_max', 'gps_alt_max', 'gps_speed_max', 'gps_bearing_max', 'gps_accuracy_max',\n",
    "                 'gps_lat_min', 'gps_long_min', 'gps_alt_min', 'gps_speed_min', 'gps_bearing_min', 'gps_accuracy_min',\n",
    "                 'gps_lat_iqr', 'gps_long_iqr', 'gps_alt_iqr', 'gps_speed_iqr', 'gps_bearing_iqr', 'gps_accuracy_iqr',\n",
    "                 'activity_id', 'activity']\n",
    "\n",
    "    # Open CSV file for writing.\n",
    "    csvFile = csv.writer(open(filePath + fileName_0, 'w', newline=\"\"), delimiter=',')\n",
    "    csvFile_1 = csv.writer(open(filePath + fileName_1, 'w', newline=\"\"), delimiter=',')\n",
    "    csvFile_2 = csv.writer(open(filePath + fileName_2, 'w', newline=\"\"), delimiter=',')\n",
    "\n",
    "    # Add the headers and data to the CSV file.\n",
    "    csvFile.writerow(headers_0)\n",
    "    csvFile.writerows(data_0)\n",
    "    csvFile_1.writerow(headers_1)\n",
    "    csvFile_1.writerows(data_1)\n",
    "    csvFile_2.writerow(headers_2)\n",
    "    csvFile_2.writerows(data_2)\n",
    "\n",
    "\n",
    "# This function calls the main process and writes all the data into CSV files.\n",
    "def prepare_data(n_seconds, overlap, cut_seconds, n_div, index):\n",
    "    # Set:\n",
    "    # 0 - Acc + GPS (all users)\n",
    "    # 1 - Acc + Magn + GPS (all users but the ones missing magnetometer)\n",
    "    # 2 - Acc + Gyro + Magn + GPS (all users but the ones missing gyroscope and magnetometer)\n",
    "\n",
    "    if index > 0:\n",
    "        process_data_split(index, n_seconds, overlap, cut_seconds)\n",
    "    else:\n",
    "        # File path and name.\n",
    "        filePath = './'\n",
    "        fileName_0 = 'sensoringData_feature_prepared_' + str(n_seconds) + '_' + str(overlap) + '_0.csv'\n",
    "        fileName_1 = 'sensoringData_feature_prepared_' + str(n_seconds) + '_' + str(overlap) + '_1.csv'\n",
    "        fileName_2 = 'sensoringData_feature_prepared_' + str(n_seconds) + '_' + str(overlap) + '_2.csv'\n",
    "\n",
    "        # Extract the table headers.\n",
    "        headers_2 = ['id', 'user', 'timestamp', 'acc_xs_mean', 'acc_ys_mean', 'acc_zs_mean', 'acc_xs_var', 'acc_ys_var',\n",
    "                     'acc_zs_var', 'acc_xs_mad', 'acc_ys_mad', 'acc_zs_mad', 'acc_xs_max', 'acc_ys_max', 'acc_zs_max',\n",
    "                     'acc_xs_min', 'acc_ys_min', 'acc_zs_min', 'acc_xs_iqr', 'acc_ys_iqr', 'acc_zs_iqr', 'gyro_xs_mean',\n",
    "                     'gyro_ys_mean', 'gyro_zs_mean', 'gyro_xs_var', 'gyro_ys_var', 'gyro_zs_var', 'gyro_xs_mad',\n",
    "                     'gyro_ys_mad', 'gyro_zs_mad', 'gyro_xs_max', 'gyro_ys_max', 'gyro_zs_max', 'gyro_xs_min',\n",
    "                     'gyro_ys_min', 'gyro_zs_min', 'gyro_xs_iqr', 'gyro_ys_iqr', 'gyro_zs_iqr', 'magn_xs_mean',\n",
    "                     'magn_ys_mean', 'magn_zs_mean', 'magn_xs_var', 'magn_ys_var', 'magn_zs_var', 'magn_xs_mad',\n",
    "                     'magn_ys_mad', 'magn_zs_mad', 'magn_xs_max', 'magn_ys_max', 'magn_zs_max', 'magn_xs_min',\n",
    "                     'magn_ys_min', 'magn_zs_min', 'magn_xs_iqr', 'magn_ys_iqr', 'magn_zs_iqr', 'gps_lat_mean',\n",
    "                     'gps_long_mean', 'gps_alt_mean', 'gps_speed_mean', 'gps_bearing_mean', 'gps_accuracy_mean',\n",
    "                     'gps_lat_var', 'gps_long_var', 'gps_alt_var', 'gps_speed_var', 'gps_bearing_var',\n",
    "                     'gps_accuracy_var', 'gps_lat_mad', 'gps_long_mad', 'gps_alt_mad', 'gps_speed_mad',\n",
    "                     'gps_bearing_mad', 'gps_accuracy_mad', 'gps_lat_max', 'gps_long_max', 'gps_alt_max',\n",
    "                     'gps_speed_max', 'gps_bearing_max', 'gps_accuracy_max', 'gps_lat_min', 'gps_long_min',\n",
    "                     'gps_alt_min', 'gps_speed_min', 'gps_bearing_min', 'gps_accuracy_min', 'gps_lat_iqr',\n",
    "                     'gps_long_iqr', 'gps_alt_iqr', 'gps_speed_iqr', 'gps_bearing_iqr', 'gps_accuracy_iqr',\n",
    "                     'activity_id', 'activity']\n",
    "\n",
    "        headers_1 = ['id', 'user', 'timestamp', 'acc_xs_mean', 'acc_ys_mean', 'acc_zs_mean', 'acc_xs_var', 'acc_ys_var',\n",
    "                     'acc_zs_var', 'acc_xs_mad', 'acc_ys_mad', 'acc_zs_mad', 'acc_xs_max', 'acc_ys_max', 'acc_zs_max',\n",
    "                     'acc_xs_min', 'acc_ys_min', 'acc_zs_min', 'acc_xs_iqr', 'acc_ys_iqr', 'acc_zs_iqr', 'magn_xs_mean',\n",
    "                     'magn_ys_mean', 'magn_zs_mean', 'magn_xs_var', 'magn_ys_var', 'magn_zs_var', 'magn_xs_mad',\n",
    "                     'magn_ys_mad', 'magn_zs_mad', 'magn_xs_max', 'magn_ys_max', 'magn_zs_max', 'magn_xs_min',\n",
    "                     'magn_ys_min', 'magn_zs_min', 'magn_xs_iqr', 'magn_ys_iqr', 'magn_zs_iqr', 'gps_lat_mean',\n",
    "                     'gps_long_mean', 'gps_alt_mean', 'gps_speed_mean', 'gps_bearing_mean', 'gps_accuracy_mean',\n",
    "                     'gps_lat_var', 'gps_long_var', 'gps_alt_var', 'gps_speed_var', 'gps_bearing_var',\n",
    "                     'gps_accuracy_var', 'gps_lat_mad', 'gps_long_mad', 'gps_alt_mad', 'gps_speed_mad',\n",
    "                     'gps_bearing_mad', 'gps_accuracy_mad', 'gps_lat_max', 'gps_long_max', 'gps_alt_max',\n",
    "                     'gps_speed_max', 'gps_bearing_max', 'gps_accuracy_max', 'gps_lat_min', 'gps_long_min',\n",
    "                     'gps_alt_min', 'gps_speed_min', 'gps_bearing_min', 'gps_accuracy_min', 'gps_lat_iqr',\n",
    "                     'gps_long_iqr', 'gps_alt_iqr', 'gps_speed_iqr', 'gps_bearing_iqr', 'gps_accuracy_iqr',\n",
    "                     'activity_id', 'activity']\n",
    "\n",
    "        headers_0 = ['id', 'user', 'timestamp', 'acc_xs_mean', 'acc_ys_mean', 'acc_zs_mean', 'acc_xs_var', 'acc_ys_var',\n",
    "                     'acc_zs_var', 'acc_xs_mad', 'acc_ys_mad', 'acc_zs_mad', 'acc_xs_max', 'acc_ys_max', 'acc_zs_max',\n",
    "                     'acc_xs_min', 'acc_ys_min', 'acc_zs_min', 'acc_xs_iqr', 'acc_ys_iqr', 'acc_zs_iqr', 'gps_lat_mean',\n",
    "                     'gps_long_mean', 'gps_alt_mean', 'gps_speed_mean', 'gps_bearing_mean', 'gps_accuracy_mean',\n",
    "                     'gps_lat_var', 'gps_long_var', 'gps_alt_var', 'gps_speed_var', 'gps_bearing_var',\n",
    "                     'gps_accuracy_var', 'gps_lat_mad', 'gps_long_mad', 'gps_alt_mad', 'gps_speed_mad',\n",
    "                     'gps_bearing_mad', 'gps_accuracy_mad', 'gps_lat_max', 'gps_long_max', 'gps_alt_max',\n",
    "                     'gps_speed_max', 'gps_bearing_max', 'gps_accuracy_max', 'gps_lat_min', 'gps_long_min',\n",
    "                     'gps_alt_min', 'gps_speed_min', 'gps_bearing_min', 'gps_accuracy_min', 'gps_lat_iqr',\n",
    "                     'gps_long_iqr', 'gps_alt_iqr', 'gps_speed_iqr', 'gps_bearing_iqr', 'gps_accuracy_iqr',\n",
    "                     'activity_id', 'activity']\n",
    "\n",
    "        i = 1\n",
    "        data_0 = []\n",
    "        data_1 = []\n",
    "        data_2 = []\n",
    "        while i <= n_div:\n",
    "            split_path_0 = 'sensoringData_feature_prepared_' + str(n_seconds) + '_' + str(\n",
    "                overlap) + '_0_split_' + str(i) + '.csv'\n",
    "            split_path_1 = 'sensoringData_feature_prepared_' + str(n_seconds) + '_' + str(\n",
    "                overlap) + '_1_split_' + str(i) + '.csv'\n",
    "            split_path_2 = 'sensoringData_feature_prepared_' + str(n_seconds) + '_' + str(\n",
    "                overlap) + '_2_split_' + str(i) + '.csv'\n",
    "\n",
    "            split_0_input = open(split_path_0, 'r')\n",
    "            split_1_input = open(split_path_1, 'r')\n",
    "            split_2_input = open(split_path_2, 'r')\n",
    "\n",
    "            for row in csv.reader(split_0_input):\n",
    "                if row[0] != \"id\":\n",
    "                    data_0.append(row)\n",
    "            for row in csv.reader(split_1_input):\n",
    "                if row[0] != \"id\":\n",
    "                    data_1.append(row)\n",
    "            for row in csv.reader(split_2_input):\n",
    "                if row[0] != \"id\":\n",
    "                    data_2.append(row)\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        # Open CSV file for writing.\n",
    "        csvFile = csv.writer(open(filePath + fileName_0, 'w', newline=\"\"), delimiter=',')\n",
    "        csvFile_1 = csv.writer(open(filePath + fileName_1, 'w', newline=\"\"), delimiter=',')\n",
    "        csvFile_2 = csv.writer(open(filePath + fileName_2, 'w', newline=\"\"), delimiter=',')\n",
    "\n",
    "        # Add the headers and data to the CSV file.\n",
    "        csvFile.writerow(headers_0)\n",
    "        csvFile.writerows(data_0)\n",
    "        csvFile_1.writerow(headers_1)\n",
    "        csvFile_1.writerows(data_1)\n",
    "        csvFile_2.writerow(headers_2)\n",
    "        csvFile_2.writerows(data_2)\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # 20, 19, 5, 8\n",
    "    if sys.argv[5]:\n",
    "        index = int(sys.argv[5])\n",
    "    else:\n",
    "        index = -1\n",
    "    startTime = time.time()\n",
    "    prepare_data(int(sys.argv[1]), float(sys.argv[2]), int(sys.argv[3]), int(sys.argv[4]), index)\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(elapsedTime)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "SVM.py\n",
    "Script used to train and test the SVM model proposed and obtaining the results.\n",
    "It is coded in a Slurm way to be executed as a job array (one job for every fold computed over the data).\n",
    "Parameters:\n",
    "\t\t- String formed by the window size, overlap size and corresponding set, divided by low bars (20_19.0_2).\n",
    "\t\t- Slurm job array index, from 1 to 10.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No display found. Using non-interactive Agg backend\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: '-f'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[1;32mIn [1], line 386\u001B[0m\n\u001B[0;32m    384\u001B[0m set_random_seed(\u001B[38;5;241m6\u001B[39m)  \u001B[38;5;66;03m# Favourite number\u001B[39;00m\n\u001B[0;32m    385\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m sys\u001B[38;5;241m.\u001B[39margv[\u001B[38;5;241m1\u001B[39m]:\n\u001B[1;32m--> 386\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mint\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43msys\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43margv\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;241;43m1\u001B[39;49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    387\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m    388\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m\n",
      "\u001B[1;31mValueError\u001B[0m: invalid literal for int() with base 10: '-f'"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import warnings\n",
    "\n",
    "# import tf as tf\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib as mpl\n",
    "\n",
    "if os.environ.get('DISPLAY', '') == '':\n",
    "    print('No display found. Using non-interactive Agg backend')\n",
    "    mpl.use('Agg')\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns\n",
    "import sys\n",
    "import itertools\n",
    "import random\n",
    "from scipy import stats\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, f1_score\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "def svm_model(case, index):\n",
    "    # Data initialization\n",
    "    sns.set(style='whitegrid', palette='muted', font_scale=1.5)\n",
    "    feat_case = case\n",
    "    set = int(feat_case.split('_')[2][0])\n",
    "    directory = 'svm_' + case.replace('.', '')\n",
    "    LABELS = ['Inactive', 'Active', 'Walking', 'Driving']\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "    case = \"svm_\" + case\n",
    "\n",
    "    if set == 2:\n",
    "        columns = ['id', 'user', 'timestamp', 'acc_xs_mean', 'acc_ys_mean', 'acc_zs_mean', 'acc_xs_var',\n",
    "                   'acc_ys_var', 'acc_zs_var', 'acc_xs_mad', 'acc_ys_mad', 'acc_zs_mad', 'acc_xs_max',\n",
    "                   'acc_ys_max', 'acc_zs_max', 'acc_xs_min', 'acc_ys_min', 'acc_zs_min', 'acc_xs_iqr',\n",
    "                   'acc_ys_iqr', 'acc_zs_iqr', 'gyro_xs_mean', 'gyro_ys_mean', 'gyro_zs_mean', 'gyro_xs_var',\n",
    "                   'gyro_ys_var', 'gyro_zs_var', 'gyro_xs_mad', 'gyro_ys_mad', 'gyro_zs_mad', 'gyro_xs_max',\n",
    "                   'gyro_ys_max', 'gyro_zs_max', 'gyro_xs_min', 'gyro_ys_min', 'gyro_zs_min', 'gyro_xs_iqr',\n",
    "                   'gyro_ys_iqr', 'gyro_zs_iqr', 'magn_xs_mean', 'magn_ys_mean', 'magn_zs_mean', 'magn_xs_var',\n",
    "                   'magn_ys_var', 'magn_zs_var', 'magn_xs_mad', 'magn_ys_mad', 'magn_zs_mad', 'magn_xs_max',\n",
    "                   'magn_ys_max', 'magn_zs_max', 'magn_xs_min', 'magn_ys_min', 'magn_zs_min', 'magn_xs_iqr',\n",
    "                   'magn_ys_iqr', 'magn_zs_iqr', 'gps_lat_mean', 'gps_long_mean', 'gps_alt_mean',\n",
    "                   'gps_speed_mean', 'gps_bearing_mean', 'gps_accuracy_mean', 'gps_lat_var', 'gps_long_var',\n",
    "                   'gps_alt_var', 'gps_speed_var', 'gps_bearing_var', 'gps_accuracy_var', 'gps_lat_mad',\n",
    "                   'gps_long_mad', 'gps_alt_mad', 'gps_speed_mad', 'gps_bearing_mad', 'gps_accuracy_mad',\n",
    "                   'gps_lat_max', 'gps_long_max', 'gps_alt_max', 'gps_speed_max', 'gps_bearing_max',\n",
    "                   'gps_accuracy_max', 'gps_lat_min', 'gps_long_min', 'gps_alt_min', 'gps_speed_min',\n",
    "                   'gps_bearing_min', 'gps_accuracy_min', 'gps_lat_iqr', 'gps_long_iqr', 'gps_alt_iqr',\n",
    "                   'gps_speed_iqr', 'gps_bearing_iqr', 'gps_accuracy_iqr', 'activity_id', 'activity']\n",
    "    else:\n",
    "        if set == 1:\n",
    "            columns = ['id', 'user', 'timestamp', 'acc_xs_mean', 'acc_ys_mean', 'acc_zs_mean', 'acc_xs_var',\n",
    "                       'acc_ys_var', 'acc_zs_var', 'acc_xs_mad', 'acc_ys_mad', 'acc_zs_mad', 'acc_xs_max',\n",
    "                       'acc_ys_max', 'acc_zs_max', 'acc_xs_min', 'acc_ys_min', 'acc_zs_min', 'acc_xs_iqr',\n",
    "                       'acc_ys_iqr', 'acc_zs_iqr', 'magn_xs_mean', 'magn_ys_mean', 'magn_zs_mean',\n",
    "                       'magn_xs_var', 'magn_ys_var', 'magn_zs_var', 'magn_xs_mad', 'magn_ys_mad', 'magn_zs_mad',\n",
    "                       'magn_xs_max', 'magn_ys_max', 'magn_zs_max', 'magn_xs_min', 'magn_ys_min', 'magn_zs_min',\n",
    "                       'magn_xs_iqr', 'magn_ys_iqr', 'magn_zs_iqr', 'gps_lat_mean', 'gps_long_mean',\n",
    "                       'gps_alt_mean', 'gps_speed_mean', 'gps_bearing_mean', 'gps_accuracy_mean', 'gps_lat_var',\n",
    "                       'gps_long_var', 'gps_alt_var', 'gps_speed_var', 'gps_bearing_var', 'gps_accuracy_var',\n",
    "                       'gps_lat_mad', 'gps_long_mad', 'gps_alt_mad', 'gps_speed_mad', 'gps_bearing_mad',\n",
    "                       'gps_accuracy_mad', 'gps_lat_max', 'gps_long_max', 'gps_alt_max', 'gps_speed_max',\n",
    "                       'gps_bearing_max', 'gps_accuracy_max', 'gps_lat_min', 'gps_long_min', 'gps_alt_min',\n",
    "                       'gps_speed_min', 'gps_bearing_min', 'gps_accuracy_min', 'gps_lat_iqr', 'gps_long_iqr',\n",
    "                       'gps_alt_iqr', 'gps_speed_iqr', 'gps_bearing_iqr', 'gps_accuracy_iqr', 'activity_id',\n",
    "                       'activity']\n",
    "        else:\n",
    "            if set == 0:\n",
    "                columns = ['id', 'user', 'timestamp', 'acc_xs_mean', 'acc_ys_mean', 'acc_zs_mean', 'acc_xs_var',\n",
    "                           'acc_ys_var', 'acc_zs_var', 'acc_xs_mad', 'acc_ys_mad', 'acc_zs_mad', 'acc_xs_max',\n",
    "                           'acc_ys_max', 'acc_zs_max', 'acc_xs_min', 'acc_ys_min', 'acc_zs_min', 'acc_xs_iqr',\n",
    "                           'acc_ys_iqr', 'acc_zs_iqr', 'gps_lat_mean', 'gps_long_mean', 'gps_alt_mean',\n",
    "                           'gps_speed_mean', 'gps_bearing_mean', 'gps_accuracy_mean', 'gps_lat_var',\n",
    "                           'gps_long_var', 'gps_alt_var', 'gps_speed_var', 'gps_bearing_var',\n",
    "                           'gps_accuracy_var', 'gps_lat_mad', 'gps_long_mad', 'gps_alt_mad', 'gps_speed_mad',\n",
    "                           'gps_bearing_mad', 'gps_accuracy_mad', 'gps_lat_max', 'gps_long_max', 'gps_alt_max',\n",
    "                           'gps_speed_max', 'gps_bearing_max', 'gps_accuracy_max', 'gps_lat_min',\n",
    "                           'gps_long_min', 'gps_alt_min', 'gps_speed_min', 'gps_bearing_min',\n",
    "                           'gps_accuracy_min', 'gps_lat_iqr', 'gps_long_iqr', 'gps_alt_iqr', 'gps_speed_iqr',\n",
    "                           'gps_bearing_iqr', 'gps_accuracy_iqr', 'activity_id', 'activity']\n",
    "\n",
    "    df = pd.read_csv('./sensoringData_feature_prepared_' + feat_case + '.csv', header=0, names=columns)\n",
    "    df.head()\n",
    "\n",
    "    # Data gathering\n",
    "    segments = []\n",
    "    labels = []\n",
    "    for i in range(0, len(df), 1):\n",
    "        label = stats.mode(df['activity'][i])[0][0]\n",
    "\n",
    "        acc_xs_mean = df['acc_xs_mean'].values[i]\n",
    "        acc_ys_mean = df['acc_ys_mean'].values[i]\n",
    "        acc_zs_mean = df['acc_zs_mean'].values[i]\n",
    "        acc_xs_var = df['acc_xs_var'].values[i]\n",
    "        acc_ys_var = df['acc_ys_var'].values[i]\n",
    "        acc_zs_var = df['acc_zs_var'].values[i]\n",
    "        acc_xs_mad = df['acc_xs_mad'].values[i]\n",
    "        acc_ys_mad = df['acc_ys_mad'].values[i]\n",
    "        acc_zs_mad = df['acc_zs_mad'].values[i]\n",
    "        acc_xs_max = df['acc_xs_max'].values[i]\n",
    "        acc_ys_max = df['acc_ys_max'].values[i]\n",
    "        acc_zs_max = df['acc_zs_max'].values[i]\n",
    "        acc_xs_min = df['acc_xs_min'].values[i]\n",
    "        acc_ys_min = df['acc_ys_min'].values[i]\n",
    "        acc_zs_min = df['acc_zs_min'].values[i]\n",
    "        acc_xs_iqr = df['acc_xs_iqr'].values[i]\n",
    "        acc_ys_iqr = df['acc_ys_iqr'].values[i]\n",
    "        acc_zs_iqr = df['acc_zs_iqr'].values[i]\n",
    "\n",
    "        if set != 0 and set != 1:\n",
    "            gyro_xs_mean = df['gyro_xs_mean'].values[i]\n",
    "            gyro_ys_mean = df['gyro_ys_mean'].values[i]\n",
    "            gyro_zs_mean = df['gyro_zs_mean'].values[i]\n",
    "            gyro_xs_var = df['gyro_xs_var'].values[i]\n",
    "            gyro_ys_var = df['gyro_ys_var'].values[i]\n",
    "            gyro_zs_var = df['gyro_zs_var'].values[i]\n",
    "            gyro_xs_mad = df['gyro_xs_mad'].values[i]\n",
    "            gyro_ys_mad = df['gyro_ys_mad'].values[i]\n",
    "            gyro_zs_mad = df['gyro_zs_mad'].values[i]\n",
    "            gyro_xs_max = df['gyro_xs_max'].values[i]\n",
    "            gyro_ys_max = df['gyro_ys_max'].values[i]\n",
    "            gyro_zs_max = df['gyro_zs_max'].values[i]\n",
    "            gyro_xs_min = df['gyro_xs_min'].values[i]\n",
    "            gyro_ys_min = df['gyro_ys_min'].values[i]\n",
    "            gyro_zs_min = df['gyro_zs_min'].values[i]\n",
    "            gyro_xs_iqr = df['gyro_xs_iqr'].values[i]\n",
    "            gyro_ys_iqr = df['gyro_ys_iqr'].values[i]\n",
    "            gyro_zs_iqr = df['gyro_zs_iqr'].values[i]\n",
    "\n",
    "        if set != 0:\n",
    "            magn_xs_mean = df['magn_xs_mean'].values[i]\n",
    "            magn_ys_mean = df['magn_ys_mean'].values[i]\n",
    "            magn_zs_mean = df['magn_zs_mean'].values[i]\n",
    "            magn_xs_var = df['magn_xs_var'].values[i]\n",
    "            magn_ys_var = df['magn_ys_var'].values[i]\n",
    "            magn_zs_var = df['magn_zs_var'].values[i]\n",
    "            magn_xs_mad = df['magn_xs_mad'].values[i]\n",
    "            magn_ys_mad = df['magn_ys_mad'].values[i]\n",
    "            magn_zs_mad = df['magn_zs_mad'].values[i]\n",
    "            magn_xs_max = df['magn_xs_max'].values[i]\n",
    "            magn_ys_max = df['magn_ys_max'].values[i]\n",
    "            magn_zs_max = df['magn_zs_max'].values[i]\n",
    "            magn_xs_min = df['magn_xs_min'].values[i]\n",
    "            magn_ys_min = df['magn_ys_min'].values[i]\n",
    "            magn_zs_min = df['magn_zs_min'].values[i]\n",
    "            magn_xs_iqr = df['magn_xs_iqr'].values[i]\n",
    "            magn_ys_iqr = df['magn_ys_iqr'].values[i]\n",
    "            magn_zs_iqr = df['magn_zs_iqr'].values[i]\n",
    "\n",
    "        gps_lat_mean = df['gps_lat_mean'].values[i]\n",
    "        gps_long_mean = df['gps_long_mean'].values[i]\n",
    "        gps_alt_mean = df['gps_alt_mean'].values[i]\n",
    "        gps_speed_mean = df['gps_speed_mean'].values[i]\n",
    "        gps_bearing_mean = df['gps_bearing_mean'].values[i]\n",
    "        gps_accuracy_mean = df['gps_accuracy_mean'].values[i]\n",
    "        gps_lat_var = df['gps_lat_var'].values[i]\n",
    "        gps_long_var = df['gps_long_var'].values[i]\n",
    "        gps_alt_var = df['gps_alt_var'].values[i]\n",
    "        gps_speed_var = df['gps_speed_var'].values[i]\n",
    "        gps_bearing_var = df['gps_bearing_var'].values[i]\n",
    "        gps_accuracy_var = df['gps_accuracy_var'].values[i]\n",
    "        gps_lat_mad = df['gps_lat_mad'].values[i]\n",
    "        gps_long_mad = df['gps_long_mad'].values[i]\n",
    "        gps_alt_mad = df['gps_alt_mad'].values[i]\n",
    "        gps_speed_mad = df['gps_speed_mad'].values[i]\n",
    "        gps_bearing_mad = df['gps_bearing_mad'].values[i]\n",
    "        gps_accuracy_mad = df['gps_accuracy_mad'].values[i]\n",
    "        gps_lat_max = df['gps_lat_max'].values[i]\n",
    "        gps_long_max = df['gps_long_max'].values[i]\n",
    "        gps_alt_max = df['gps_alt_max'].values[i]\n",
    "        gps_speed_max = df['gps_speed_max'].values[i]\n",
    "        gps_bearing_max = df['gps_bearing_max'].values[i]\n",
    "        gps_accuracy_max = df['gps_accuracy_max'].values[i]\n",
    "        gps_lat_min = df['gps_lat_min'].values[i]\n",
    "        gps_long_min = df['gps_long_min'].values[i]\n",
    "        gps_alt_min = df['gps_alt_min'].values[i]\n",
    "        gps_speed_min = df['gps_speed_min'].values[i]\n",
    "        gps_bearing_min = df['gps_bearing_min'].values[i]\n",
    "        gps_accuracy_min = df['gps_accuracy_min'].values[i]\n",
    "        gps_lat_iqr = df['gps_lat_iqr'].values[i]\n",
    "        gps_long_iqr = df['gps_long_iqr'].values[i]\n",
    "        gps_alt_iqr = df['gps_alt_iqr'].values[i]\n",
    "        gps_speed_iqr = df['gps_speed_iqr'].values[i]\n",
    "        gps_bearing_iqr = df['gps_bearing_iqr'].values[i]\n",
    "        gps_accuracy_iqr = df['gps_accuracy_iqr'].values[i]\n",
    "\n",
    "        if set == 2:\n",
    "            segments.append(\n",
    "                [acc_xs_mean, acc_ys_mean, acc_zs_mean, acc_xs_var, acc_ys_var, acc_zs_var, acc_xs_mad,\n",
    "                 acc_ys_mad, acc_zs_mad, acc_xs_max, acc_ys_max, acc_zs_max, acc_xs_min, acc_ys_min, acc_zs_min,\n",
    "                 acc_xs_iqr, acc_ys_iqr, acc_zs_iqr, gyro_xs_mean, gyro_ys_mean, gyro_zs_mean, gyro_xs_var,\n",
    "                 gyro_ys_var, gyro_zs_var, gyro_xs_mad, gyro_ys_mad, gyro_zs_mad, gyro_xs_max, gyro_ys_max,\n",
    "                 gyro_zs_max, gyro_xs_min, gyro_ys_min, gyro_zs_min, gyro_xs_iqr, gyro_ys_iqr, gyro_zs_iqr,\n",
    "                 magn_xs_mean, magn_ys_mean, magn_zs_mean, magn_xs_var, magn_ys_var, magn_zs_var, magn_xs_mad,\n",
    "                 magn_ys_mad, magn_zs_mad, magn_xs_max, magn_ys_max, magn_zs_max, magn_xs_min, magn_ys_min,\n",
    "                 magn_zs_min, magn_xs_iqr, magn_ys_iqr, magn_zs_iqr, gps_lat_mean, gps_long_mean, gps_alt_mean,\n",
    "                 gps_speed_mean, gps_bearing_mean, gps_accuracy_mean, gps_lat_var, gps_long_var, gps_alt_var,\n",
    "                 gps_speed_var, gps_bearing_var, gps_accuracy_var, gps_lat_mad, gps_long_mad, gps_alt_mad,\n",
    "                 gps_speed_mad, gps_bearing_mad, gps_accuracy_mad, gps_lat_max, gps_long_max, gps_alt_max,\n",
    "                 gps_speed_max, gps_bearing_max, gps_accuracy_max, gps_lat_min, gps_long_min, gps_alt_min,\n",
    "                 gps_speed_min, gps_bearing_min, gps_accuracy_min, gps_lat_iqr, gps_long_iqr, gps_alt_iqr,\n",
    "                 gps_speed_iqr, gps_bearing_iqr, gps_accuracy_iqr])\n",
    "        else:\n",
    "            if set == 1:\n",
    "                segments.append(\n",
    "                    [acc_xs_mean, acc_ys_mean, acc_zs_mean, acc_xs_var, acc_ys_var, acc_zs_var, acc_xs_mad,\n",
    "                     acc_ys_mad, acc_zs_mad, acc_xs_max, acc_ys_max, acc_zs_max, acc_xs_min, acc_ys_min,\n",
    "                     acc_zs_min, acc_xs_iqr, acc_ys_iqr, acc_zs_iqr, magn_xs_mean, magn_ys_mean, magn_zs_mean,\n",
    "                     magn_xs_var, magn_ys_var, magn_zs_var, magn_xs_mad, magn_ys_mad, magn_zs_mad, magn_xs_max,\n",
    "                     magn_ys_max, magn_zs_max, magn_xs_min, magn_ys_min, magn_zs_min, magn_xs_iqr, magn_ys_iqr,\n",
    "                     magn_zs_iqr, gps_lat_mean, gps_long_mean, gps_alt_mean, gps_speed_mean, gps_bearing_mean,\n",
    "                     gps_accuracy_mean, gps_lat_var, gps_long_var, gps_alt_var, gps_speed_var, gps_bearing_var,\n",
    "                     gps_accuracy_var, gps_lat_mad, gps_long_mad, gps_alt_mad, gps_speed_mad, gps_bearing_mad,\n",
    "                     gps_accuracy_mad, gps_lat_max, gps_long_max, gps_alt_max, gps_speed_max, gps_bearing_max,\n",
    "                     gps_accuracy_max, gps_lat_min, gps_long_min, gps_alt_min, gps_speed_min, gps_bearing_min,\n",
    "                     gps_accuracy_min, gps_lat_iqr, gps_long_iqr, gps_alt_iqr, gps_speed_iqr, gps_bearing_iqr,\n",
    "                     gps_accuracy_iqr])\n",
    "            else:\n",
    "                if set == 0:\n",
    "                    segments.append(\n",
    "                        [acc_xs_mean, acc_ys_mean, acc_zs_mean, acc_xs_var, acc_ys_var, acc_zs_var, acc_xs_mad,\n",
    "                         acc_ys_mad, acc_zs_mad, acc_xs_max, acc_ys_max, acc_zs_max, acc_xs_min, acc_ys_min,\n",
    "                         acc_zs_min, acc_xs_iqr, acc_ys_iqr, acc_zs_iqr, gps_lat_mean, gps_long_mean,\n",
    "                         gps_alt_mean, gps_speed_mean, gps_bearing_mean, gps_accuracy_mean, gps_lat_var,\n",
    "                         gps_long_var, gps_alt_var, gps_speed_var, gps_bearing_var, gps_accuracy_var,\n",
    "                         gps_lat_mad, gps_long_mad, gps_alt_mad, gps_speed_mad, gps_bearing_mad,\n",
    "                         gps_accuracy_mad, gps_lat_max, gps_long_max, gps_alt_max, gps_speed_max,\n",
    "                         gps_bearing_max, gps_accuracy_max, gps_lat_min, gps_long_min, gps_alt_min,\n",
    "                         gps_speed_min, gps_bearing_min, gps_accuracy_min, gps_lat_iqr, gps_long_iqr,\n",
    "                         gps_alt_iqr, gps_speed_iqr, gps_bearing_iqr, gps_accuracy_iqr])\n",
    "        labels.append(label)\n",
    "\n",
    "    segments = np.asarray(segments, dtype=np.float32)\n",
    "    for i in range(0, len(labels), 1):\n",
    "        if labels[i] == \"Inactive\":\n",
    "            labels[i] = 0\n",
    "        else:\n",
    "            if labels[i] == \"Active\":\n",
    "                labels[i] = 1\n",
    "            else:\n",
    "                if labels[i] == \"Walking\":\n",
    "                    labels[i] = 2\n",
    "                else:\n",
    "                    if labels[i] == \"Driving\":\n",
    "                        labels[i] = 3\n",
    "    labels = np.asarray(labels, dtype=np.int)\n",
    "\n",
    "    n_splits = 10\n",
    "\n",
    "    if index > -1:\n",
    "        split_fold = index - 1\n",
    "\n",
    "        kf = StratifiedKFold(n_splits=n_splits)\n",
    "        train_idx, test_idx = list(kf.split(segments, labels))[split_fold]\n",
    "\n",
    "        train_x = segments[train_idx]\n",
    "        train_y = labels[train_idx]\n",
    "        test_x = segments[test_idx]\n",
    "        test_y = labels[test_idx]\n",
    "\n",
    "        scaler = StandardScaler()\n",
    "        train_x = scaler.fit_transform(train_x)\n",
    "        test_x = scaler.transform(test_x)\n",
    "\n",
    "        kf_2 = StratifiedKFold(n_splits=n_splits)\n",
    "        train_idx_2, test_idx_2 = list(kf_2.split(train_x, train_y))[split_fold]\n",
    "\n",
    "        train_split_x = train_x[train_idx_2]\n",
    "        train_split_y = train_y[train_idx_2]\n",
    "        test_split_x = train_x[test_idx_2]\n",
    "        test_split_y = train_y[test_idx_2]\n",
    "\n",
    "        cs = [1, 10, 100, 1000, 10000]\n",
    "        gammas = [0.0001, 0.001, 0.01, 0.1, 1]\n",
    "        degrees = [1, 2, 3, 4]\n",
    "        lin_comb = list(itertools.product(['linear'], cs))\n",
    "        rbf_comb = list(itertools.product(['rbf'], cs, gammas))\n",
    "        poly_comb = list(itertools.product(['poly'], cs, gammas, degrees))\n",
    "        models = []\n",
    "        f1_scores = []\n",
    "        combinations = []\n",
    "        for element in lin_comb:\n",
    "            combinations.append(element)\n",
    "        for element in rbf_comb:\n",
    "            combinations.append(element)\n",
    "        for element in poly_comb:\n",
    "            combinations.append(element)\n",
    "\n",
    "        print(\"# Tuning hyper-parameters for: \" + str(split_fold))\n",
    "        print()\n",
    "\n",
    "        for (kernel, C) in lin_comb:\n",
    "            model = OneVsRestClassifier(SVC(max_iter=1000, kernel=kernel, C=C))\n",
    "            model.fit(train_split_x, train_split_y)\n",
    "\n",
    "            models.append(model)\n",
    "            y_true, y_pred = test_split_y, model.predict(test_split_x)\n",
    "\n",
    "            f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "            f1_scores.append(f1)\n",
    "            print(str(f1) + ' | (' + str(kernel) + ', ' + str(C) + ')')\n",
    "\n",
    "        for (kernel, C, gamma) in rbf_comb:\n",
    "            model = OneVsRestClassifier(SVC(max_iter=1000, kernel=kernel, C=C, gamma=gamma))\n",
    "            model.fit(train_split_x, train_split_y)\n",
    "\n",
    "            models.append(model)\n",
    "            y_true, y_pred = test_split_y, model.predict(test_split_x)\n",
    "\n",
    "            f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "            f1_scores.append(f1)\n",
    "            print(str(f1) + ' | (' + str(kernel) + ', ' + str(C) + ', ' + str(gamma) + ')')\n",
    "\n",
    "        for (kernel, C, gamma, degree) in poly_comb:\n",
    "            model = OneVsRestClassifier(SVC(max_iter=1000, kernel=kernel, C=C, gamma=gamma, degree=degree))\n",
    "            model.fit(train_split_x, train_split_y)\n",
    "\n",
    "            models.append(model)\n",
    "            y_true, y_pred = test_split_y, model.predict(test_split_x)\n",
    "\n",
    "            f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "            f1_scores.append(f1)\n",
    "            print(str(f1) + ' | (' + str(kernel) + ', ' + str(C) + ', ' + str(gamma) + ', ' + str(degree) + ')')\n",
    "\n",
    "        mf_index = f1_scores.index(max(f1_scores))\n",
    "        print()\n",
    "        print(\"# Best hyper-parameter combination: \" + str(combinations[mf_index]))\n",
    "        print()\n",
    "\n",
    "        print(\"Detailed classification report:\")\n",
    "        print()\n",
    "        print(\"The model is trained on the full development set.\")\n",
    "        print(\"The scores are computed on the full evaluation set.\")\n",
    "        print()\n",
    "        y_true, y_pred = test_y, models[mf_index].predict(test_x)\n",
    "        print(classification_report(y_true, y_pred))\n",
    "        print()\n",
    "\n",
    "        confusion_matrix = metrics.confusion_matrix(y_true, y_pred)\n",
    "        df_cm = pd.DataFrame(data=confusion_matrix.astype(float))\n",
    "        df_cm.to_csv(directory + '/confusion_matrix_' + str(split_fold) + \"_\" + case.replace('.', '') + '.csv',\n",
    "                     sep=',', header=True, float_format='%.2f', index=False)\n",
    "        plt.figure(figsize=(16, 14))\n",
    "        sns.heatmap(confusion_matrix, xticklabels=LABELS, yticklabels=LABELS, annot=True, fmt=\"d\")\n",
    "        plt.title(\"Confusion matrix\")\n",
    "        plt.ylabel('True label')\n",
    "        plt.xlabel('Predicted label')\n",
    "        plt.savefig(directory + '/confusion_matrix_' + str(split_fold) + \"_\" + case.replace('.', ''))\n",
    "\n",
    "        linear_scores = open(directory + '/linear_scores_' + str(split_fold) + '.csv', 'w', newline=\"\")\n",
    "        linear_scores_writer = csv.writer(linear_scores, delimiter=\",\")\n",
    "        linear_scores_writer.writerow(f1_scores[0:5])\n",
    "        rbf_scores = open(directory + '/rbf_scores_' + str(split_fold) + '.csv', 'w', newline=\"\")\n",
    "        rbf_scores_writer = csv.writer(rbf_scores, delimiter=\",\")\n",
    "        rbf_scores_writer.writerow(f1_scores[5:30])\n",
    "        poly_scores = open(directory + '/poly_scores_' + str(split_fold) + '.csv', 'w', newline=\"\")\n",
    "        poly_scores_writer = csv.writer(poly_scores, delimiter=\",\")\n",
    "        poly_scores_writer.writerow(f1_scores[30:130])\n",
    "\n",
    "        linear_scores.close()\n",
    "        rbf_scores.close()\n",
    "        poly_scores.close()\n",
    "\n",
    "\n",
    "def set_random_seed(seed_arg):\n",
    "    seed = int(seed_arg)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    # tf.set_random_seed(seed)\n",
    "    return seed\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    set_random_seed(6)  # Favourite number\n",
    "    if sys.argv[1]:\n",
    "        index = int(sys.argv[1])\n",
    "    else:\n",
    "        index = -1\n",
    "    startTime = time.time()\n",
    "    svm_model(sys.argv[1], index)\n",
    "    elapsedTime = time.time() - startTime\n",
    "    print(elapsedTime)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}